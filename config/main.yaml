caption_sentence_prototype: [
    "a photo of {classname}.",  # caption used to encode classes in language models. {classname} is replaced by the class names.
    3  # location of the {classname} token
]


datasets:
  CIFAR10: /path/to/dataset
  CIFAR100: /path/to/dataset
  SVHN: /path/to/dataset
  CUB: /path/to/dataset
  MNIST: /path/to/dataset
  FashionMNIST: /path/to/dataset
  ImageNet: /path/to/dataset
  ImageNet150: /path/to/dataset
  enwiki:
    train: /path/to/dataset
    val: /path/to/dataset
    full: /path/to/dataset

visual_words: "../visual_words.txt"
vocabulary: "../vocab.txt"
visual_word_embeddings: "../visual_word_embeddings"
analogy_path: /path/to/analogy

models:
  visual: [
      "RN50",
      "BiT-M-R50x1",
      "geirhos-resnet50_trained_on_SIN_and_IN_then_finetuned_on_IN",
      "geirhos-resnet50_trained_on_SIN_and_IN",
      "geirhos-resnet50_trained_on_SIN",
      "madry-imagenet_l2_3_0",
      "madry-imagenet_linf_8",
      "madry-imagenet_linf_4",
    #    "semi-supervised-YFCC100M",
    #    "semi-weakly-supervised-instagram",
  ]
  multimodal: [
      "CLIP-RN50",
      "virtex",
      "TSM-v",
      "ICMLM",
  ]
  textual: [
      "GPT2",
      "BERT",
  ]
